# PaperReading

1. Skip N-grams and Ranking Functions for Predicting Script Events
2. A Structured Self-Attentive Sentence Embedding
3. Attention Is All You Need
4. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding